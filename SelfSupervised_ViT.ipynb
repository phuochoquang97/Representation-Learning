{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3eqhJt7GchZi"
   },
   "source": [
    "# Lab: MAE - Self-Supervised Training of ViT in Pytorch\n",
    "\n",
    "For any remark or suggestion on this lab, please feel free to contact me at:\n",
    "\n",
    "- loic.lefolgoc@telecom-paris.fr\n",
    "\n",
    "### Objective:\n",
    "\n",
    "We are going to pretrain a Vision Transformer (ViT) using the Masked Auto-Encoding approach, before fine-tuning it for image recognition. We will use this model on a well-known dataset: CIFAR-10 https://www.cs.toronto.edu/~kriz/cifar.html.\n",
    "\n",
    "The model will be implemented using the Pytorch environment : https://pytorch.org/.\n",
    "    \n",
    "### Student: HO Quang Phuoc, Master MVA, ENS Paris-Saclay"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Cgyu2GBVW192"
   },
   "source": [
    "# Load packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "executionInfo": {
     "elapsed": 18988,
     "status": "ok",
     "timestamp": 1740343425387,
     "user": {
      "displayName": "Phuoc Ho Quang",
      "userId": "17998449024561865035"
     },
     "user_tz": -60
    },
    "id": "1Qj5KY79W192"
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import copy\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bJZ6kzxLXhio"
   },
   "source": [
    "# Check and install some packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "executionInfo": {
     "elapsed": 3387,
     "status": "ok",
     "timestamp": 1740343428772,
     "user": {
      "displayName": "Phuoc Ho Quang",
      "userId": "17998449024561865035"
     },
     "user_tz": -60
    },
    "id": "NgY0n-RnXj9e"
   },
   "outputs": [],
   "source": [
    "import subprocess\n",
    "import sys\n",
    "\n",
    "\n",
    "def install_if_needed(package):\n",
    "    try:\n",
    "        __import__(package)\n",
    "    except ImportError:\n",
    "        subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", package])\n",
    "\n",
    "\n",
    "# Check and install required packages\n",
    "install_if_needed(\"einops\")\n",
    "install_if_needed(\"timm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "executionInfo": {
     "elapsed": 12,
     "status": "ok",
     "timestamp": 1740343428787,
     "user": {
      "displayName": "Phuoc Ho Quang",
      "userId": "17998449024561865035"
     },
     "user_tz": -60
    },
    "id": "WQazu22-XquB"
   },
   "outputs": [],
   "source": [
    "# Import modules after ensuring installation\n",
    "from einops import rearrange, repeat\n",
    "from einops.layers.torch import Rearrange\n",
    "from timm.layers import trunc_normal_\n",
    "from timm.models.vision_transformer import Block"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "M5D5BY20W1-m"
   },
   "source": [
    "# Load the dataset: CIFAR-10\n",
    "\n",
    "We are going to train a vision transformer on a well-known vision dataset : CIFAR10. CIFAR10 consists of $60,000$ $32\\times 32$ color images of $10$ different object classes, with 6000 images per class. There are 50000 training images and 10000 test images.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "executionInfo": {
     "elapsed": 13,
     "status": "ok",
     "timestamp": 1740343428808,
     "user": {
      "displayName": "Phuoc Ho Quang",
      "userId": "17998449024561865035"
     },
     "user_tz": -60
    },
    "id": "5Al5b-S37T4A"
   },
   "outputs": [],
   "source": [
    "# The CIFAR10 categories\n",
    "cifar_10_list = [\n",
    "    \"airplane\",\n",
    "    \"automobile\",\n",
    "    \"bird\",\n",
    "    \"cat\",\n",
    "    \"deer\",\n",
    "    \"dog\",\n",
    "    \"frog\",\n",
    "    \"horse\",\n",
    "    \"ship\",\n",
    "    \"truck\",\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fp37mAZFTPFp"
   },
   "source": [
    "We import the CIFAR-10 data and carry out some pre-processing :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 23360,
     "status": "ok",
     "timestamp": 1740343479987,
     "user": {
      "displayName": "Phuoc Ho Quang",
      "userId": "17998449024561865035"
     },
     "user_tz": -60
    },
    "id": "k15abDeRW1-m",
    "outputId": "c3f6ff45-bb97-4b54-95ea-adab85dc8880"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar-10-python.tar.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 170M/170M [00:18<00:00, 9.20MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/cifar-10-python.tar.gz to ./data\n",
      "Dataset CIFAR10\n",
      "    Number of datapoints: 50000\n",
      "    Root location: ./data\n",
      "    Split: Train\n",
      "    StandardTransform\n",
      "Transform: Compose(\n",
      "               ToTensor()\n",
      "           )\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "# Convert input to Pytorch tensors\n",
    "input_transform = transforms.Compose([transforms.ToTensor()])\n",
    "\n",
    "# Retrieve CIFAR training data\n",
    "cifar_trainset = datasets.CIFAR10(\n",
    "    root=\"./data\", train=True, download=True, transform=input_transform\n",
    ")\n",
    "print(cifar_trainset)\n",
    "\n",
    "# Retrieve test data\n",
    "cifar_testset = datasets.CIFAR10(\n",
    "    root=\"./data\", train=False, download=True, transform=input_transform\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 208,
     "status": "ok",
     "timestamp": 1740343480193,
     "user": {
      "displayName": "Phuoc Ho Quang",
      "userId": "17998449024561865035"
     },
     "user_tz": -60
    },
    "id": "E1fWrMSmR16_",
    "outputId": "2c20b59d-ac7b-4c75-a7b3-86eeb297242f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10000, 3, 32, 32])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extract the test data and labels for later (visualization of the results)\n",
    "X_test = torch.from_numpy(cifar_testset.data / 255.0).float().permute(0, 3, 1, 2)\n",
    "Y_test = torch.tensor(cifar_testset.targets, dtype=torch.uint8)\n",
    "X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XrGI_L3OW1-3"
   },
   "source": [
    "# Build the MAE model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xfbsac9FfYNE"
   },
   "source": [
    "An MAE model consists of a standard transformer encoder and of a decoder.\n",
    "\n",
    "The encoder is in charge of learning patch representations (token embeddings) that somehow capture their semantic context (the object they belong to, their situation with respect to the other tokens, etc.) The encoder does not see all patches in the image (many patches are masked).\n",
    "\n",
    "The decoder is in charge of reconstructing the full image from the reduced set of token embeddings seen by the encoder. The decoder is similar in design to the encoder, except it has a final regression head that projects each spatial token to a patch (predicting pixel values of the reconstructed image).\n",
    "\n",
    "Another difference in implementation of the MAE encoder/decoder (compared to a standard ViT encoder) is that they shuffle/mask/remove (MAE encoder), or unshuffle (MAE decoder) spatial tokens in the forward pass."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xFXvjiLzkDZk"
   },
   "source": [
    "<br>Most of the pieces of code you will have to complete in the `MAE_Encoder` and `MAE_Decoder` relate to these specificities. We are going to build the model step-by-step."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QRo6s7Sner39"
   },
   "source": [
    "Let's complete helper functions first. Use `shuffle` and `argsort` from numpy to complete the function `random_indices` according to its description."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "executionInfo": {
     "elapsed": 10,
     "status": "ok",
     "timestamp": 1740343480214,
     "user": {
      "displayName": "Phuoc Ho Quang",
      "userId": "17998449024561865035"
     },
     "user_tz": -60
    },
    "id": "Fdol2YmJBQ7M"
   },
   "outputs": [],
   "source": [
    "def random_indices(size: int):\n",
    "    \"\"\"\n",
    "    Returns two outputs:\n",
    "    forward_indices: np.array (size,) An array of indices between 0 and size-1 in random order\n",
    "    backward_indices: np.array (size,) The array of indices that reorders forward_indices back to an ordered, increasing list of numbers\n",
    "      i.e. forward_indices[backward_indices] = np.arange(size)\n",
    "    \"\"\"\n",
    "    forward_indices = np.arange(size)  # Create a sequential array of indices\n",
    "    np.random.shuffle(forward_indices)  # Shuffle indices randomly\n",
    "    backward_indices = np.argsort(forward_indices)  # Compute inverse mapping\n",
    "    return forward_indices, backward_indices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "q3-hxpS8fEpr"
   },
   "source": [
    "Use `torch.gather` to complete the helper function `take_indices` according to its description."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "executionInfo": {
     "elapsed": 31,
     "status": "ok",
     "timestamp": 1740343480254,
     "user": {
      "displayName": "Phuoc Ho Quang",
      "userId": "17998449024561865035"
     },
     "user_tz": -60
    },
    "id": "TXa3PAZaBRAL"
   },
   "outputs": [],
   "source": [
    "def take_indices(tokens, indices):\n",
    "    \"\"\"\n",
    "    tokens: (N, B, C) tensor, tokens[n, b, c] is the c-th entry of the n-th token in the b-th token sequence in the minibatch\n",
    "    indices: (N', B) tensor, giving the indices of the N' tokens to retrieve from the token sequence, for all token sequences in the minibatch\n",
    "\n",
    "    output: (N', B, C) tensor, corresponding to the N' tokens corresponding to the desired indices\n",
    "    \"\"\"\n",
    "    return torch.gather(\n",
    "        tokens, 0, repeat(indices, \"n_prime b -> n_prime b c\", c=tokens.shape[-1])\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NLTcuc3lvPHG"
   },
   "source": [
    "<br>Right after tokenizing an image into patches, creating the patch embeddings, and adding positional embeddings, the `MAE_Encoder` shuffles the token embeddings and discards some of them. This is done by the `PatchShuffle` module below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "executionInfo": {
     "elapsed": 19,
     "status": "ok",
     "timestamp": 1740343480271,
     "user": {
      "displayName": "Phuoc Ho Quang",
      "userId": "17998449024561865035"
     },
     "user_tz": -60
    },
    "id": "86YL75HHBRL3"
   },
   "outputs": [],
   "source": [
    "class PatchShuffle(torch.nn.Module):\n",
    "    \"\"\"\n",
    "    Shuffles the token embeddings for a minibatch (different reordering for different minibatch samples),\n",
    "    then discards some of them.\n",
    "\n",
    "    Attributes:\n",
    "      ratio: Scalar in (0,1): the fraction of discarded patches\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, ratio) -> None:\n",
    "        super().__init__()\n",
    "        assert 0 < ratio < 1, \"ratio must be in the range (0, 1)\"\n",
    "        self.ratio = ratio\n",
    "\n",
    "    def forward(self, patches: torch.Tensor):\n",
    "        \"\"\"\n",
    "        Takes the token embeddings (patches) as input.\n",
    "        Generates a random reordering (forward_indices) and the mapping back to the original order (backward_indices)\n",
    "        and shuffles token embeddings accordingly. Then, discards a number of patches.\n",
    "\n",
    "        Args:\n",
    "            patches: (N, B, C) tensor, where N is the number of patches, B is the batch size, and C is the embedding dimension.\n",
    "\n",
    "        Returns:\n",
    "            patches: (N_kept, B, C) tensor, the shuffled and reduced patches.\n",
    "            forward_indices: (N_kept, B) tensor, the indices used to shuffle the patches.\n",
    "            backward_indices: (N, B) tensor, the indices to restore the original order.\n",
    "        \"\"\"\n",
    "        N, B, C = patches.shape\n",
    "        N_kept = int(N * (1 - self.ratio))  # Number of patches to keep\n",
    "\n",
    "        # Generate random forward and backward indices for each sequence in the minibatch\n",
    "        indices = [\n",
    "            random_indices(N) for _ in range(B)\n",
    "        ]  # List of (forward_indices, backward_indices) tuples\n",
    "\n",
    "        # Stack forward and backward indices into tensors\n",
    "        forward_indexes = torch.as_tensor(\n",
    "            np.stack([i[0] for i in indices], axis=-1), dtype=torch.long\n",
    "        ).to(patches.device)\n",
    "        backward_indexes = torch.as_tensor(\n",
    "            np.stack([i[1] for i in indices], axis=-1), dtype=torch.long\n",
    "        ).to(patches.device)\n",
    "\n",
    "        # Shuffle patches based on forward indices\n",
    "        patches = take_indices(patches, forward_indexes)\n",
    "\n",
    "        # Discard patches based on N_kept\n",
    "        patches = patches[:N_kept]\n",
    "\n",
    "        return patches, forward_indexes, backward_indexes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NGS_JxlkK42f"
   },
   "source": [
    "<br>We now turn towards implementing the `MAE_Encoder`. It contains:\n",
    "- a 'stem' `self.patchify` that turns images into token embeddings;\n",
    "- positional embeddings and the cls token;\n",
    "- transformer encoder blocks `Block` from the `timm` library (that implement the MHSA layer, feed-forward layer, and put it all together);\n",
    "- and finally, a `PatchShuffle` layer as implemented above, to shuffle and drop tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "executionInfo": {
     "elapsed": 45,
     "status": "ok",
     "timestamp": 1740343480317,
     "user": {
      "displayName": "Phuoc Ho Quang",
      "userId": "17998449024561865035"
     },
     "user_tz": -60
    },
    "id": "XWcRdWSHHS73"
   },
   "outputs": [],
   "source": [
    "class MAE_Encoder(torch.nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        image_size=32,\n",
    "        patch_size=2,\n",
    "        emb_dim=192,\n",
    "        mlp_ratio=4,\n",
    "        num_layer=12,\n",
    "        num_head=3,\n",
    "        mask_ratio=0.75,\n",
    "    ) -> None:\n",
    "        super().__init__()\n",
    "\n",
    "        # Class token and positional embeddings\n",
    "        self.cls_token = torch.nn.Parameter(torch.zeros(1, 1, emb_dim))\n",
    "        self.pos_embedding = torch.nn.Parameter(\n",
    "            torch.zeros((image_size // patch_size) ** 2, 1, emb_dim)\n",
    "        )\n",
    "\n",
    "        # Tokenization / patch embedding layer\n",
    "        self.patchify = torch.nn.Conv2d(3, emb_dim, patch_size, patch_size)\n",
    "\n",
    "        # Token shuffling layer\n",
    "        self.shuffle = PatchShuffle(mask_ratio)\n",
    "\n",
    "        # Transformer layers\n",
    "        self.transformer = torch.nn.Sequential(\n",
    "            *[Block(emb_dim, num_head, mlp_ratio=mlp_ratio) for _ in range(num_layer)]\n",
    "        )\n",
    "        self.layer_norm = torch.nn.LayerNorm(emb_dim)\n",
    "\n",
    "        # Initialize weights\n",
    "        self.init_weight()\n",
    "\n",
    "    def init_weight(self):\n",
    "        trunc_normal_(self.cls_token, std=0.02)\n",
    "        trunc_normal_(self.pos_embedding, std=0.02)\n",
    "\n",
    "    def forward(self, img):\n",
    "        \"\"\"\n",
    "        Takes as input images in (B, C, H, W) format.\n",
    "        Returns the token embeddings (including the cls token) after shuffling\n",
    "        and discarding some tokens. Also returns the backward indices that allow us\n",
    "        to \"unshuffle\" tokens to their original location in the sequence.\n",
    "\n",
    "        Args:\n",
    "            img: (B, C, H, W) tensor, input images.\n",
    "\n",
    "        Returns:\n",
    "            features: (N, B, C) tensor, encoded token embeddings (including cls token).\n",
    "            backward_indices: (N, B) tensor, indices to unshuffle tokens to their original order.\n",
    "        \"\"\"\n",
    "        B = img.shape[0]  # Batch size\n",
    "\n",
    "        # Tokenize the image into patches\n",
    "        patches = self.patchify(img)  # (B, emb_dim, H', W')\n",
    "        patches = rearrange(\n",
    "            patches, \"b c h w -> (h w) b c\"\n",
    "        )  # (N, B, C), where N = (H // patch_size) * (W // patch_size)\n",
    "\n",
    "        # Add positional embeddings\n",
    "        patches = patches + self.pos_embedding\n",
    "\n",
    "        # Shuffle tokens and keep only a subset\n",
    "        patches, forward_indices, backward_indices = self.shuffle(patches)\n",
    "\n",
    "        # Add class token\n",
    "        cls_tokens = self.cls_token.expand(-1, B, -1)  # (1, B, C)\n",
    "        patches = torch.cat([cls_tokens, patches], dim=0)  # (N + 1, B, C)\n",
    "\n",
    "        # Process through the transformer encoder\n",
    "        patches = rearrange(patches, \"n b c -> b n c\")  # (B, N + 1, C)\n",
    "        features = self.transformer(patches)\n",
    "        features = self.layer_norm(features)\n",
    "\n",
    "        # Reshape tokens from (B, N + 1, C) to (N + 1, B, C) before returning\n",
    "        features = rearrange(features, \"b n c -> n b c\")\n",
    "        return features, backward_indices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QeT8bbYWbQZ4"
   },
   "source": [
    "<br>Next is the `MAE_Decoder`. It contains:\n",
    "- positional embeddings, and a special learnable `mask_token` replacing the token embeddings for the tokens that were masked out in the first phase;\n",
    "- transformer decoder blocks identical to the encoder blocks *i.e.*, the same `Block` module from the `timm` library;\n",
    "- a regression head self.head, that is a `torch.nn.Linear` layer projecting $(N, B, C)$ tensors to $(N, B, C_{in})$ tensors, where $C_{in}$ is the number of entries in an RGB patch of size `patch_size`;\n",
    "- the regression head is complemented by a `self.patch2img` layer that rearranges $(N, B, C_{in})$ tensors to $(B, 3, H, W)$ tensors.\n",
    "\n",
    "In the forward pass, the `MAE_Decoder` takes the output of the `MAE_Encoder`. It generates reconstructed images and masks of the same size as reconstructed images, with 1's in the masked tokens and 0's in the retained tokens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "executionInfo": {
     "elapsed": 17,
     "status": "ok",
     "timestamp": 1740343480336,
     "user": {
      "displayName": "Phuoc Ho Quang",
      "userId": "17998449024561865035"
     },
     "user_tz": -60
    },
    "id": "1r_vm6TRH3mm"
   },
   "outputs": [],
   "source": [
    "class MAE_Decoder(torch.nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        image_size=32,\n",
    "        patch_size=2,\n",
    "        emb_dim=192,\n",
    "        mlp_ratio=4,\n",
    "        num_layer=4,\n",
    "        num_head=3,\n",
    "    ) -> None:\n",
    "        super().__init__()\n",
    "\n",
    "        self.mask_token = torch.nn.Parameter(torch.zeros(1, 1, emb_dim))\n",
    "        self.pos_embedding = torch.nn.Parameter(\n",
    "            torch.zeros((image_size // patch_size) ** 2 + 1, 1, emb_dim)\n",
    "        )\n",
    "\n",
    "        # Transformer layers\n",
    "        self.transformer = torch.nn.Sequential(\n",
    "            *[Block(emb_dim, num_head, mlp_ratio=mlp_ratio) for _ in range(num_layer)]\n",
    "        )\n",
    "\n",
    "        # Regression head to predict pixel values\n",
    "        self.head = torch.nn.Linear(emb_dim, patch_size**2 * 3)\n",
    "        self.patch2img = Rearrange(\n",
    "            \"(h w) b (c p1 p2) -> b c (h p1) (w p2)\",\n",
    "            p1=patch_size,\n",
    "            p2=patch_size,\n",
    "            h=image_size // patch_size,\n",
    "        )\n",
    "\n",
    "        self.init_weight()\n",
    "\n",
    "    def init_weight(self):\n",
    "        trunc_normal_(self.mask_token, std=0.02)\n",
    "        trunc_normal_(self.pos_embedding, std=0.02)\n",
    "\n",
    "    def forward(self, features, backward_indices):\n",
    "        N_, B, C = features.shape\n",
    "        N = backward_indices.shape[0]\n",
    "\n",
    "        # Adding the class token index (0) to the indices because the cls token is part of features\n",
    "        backward_indices_augmented = torch.cat(\n",
    "            [torch.zeros(1, B).to(backward_indices), backward_indices + 1], dim=0\n",
    "        )\n",
    "\n",
    "        # Adding the mask tokens to the encoded features, then shuffling tokens\n",
    "        # back to their correct (original) positions in the token sequence\n",
    "        features = torch.cat(\n",
    "            [features, self.mask_token.expand(N + 1 - N_, B, -1)], dim=0\n",
    "        )\n",
    "        features = take_indices(features, backward_indices_augmented)\n",
    "\n",
    "        # Adding positional embeddings\n",
    "        features = features + self.pos_embedding\n",
    "\n",
    "        # Run the tokens through the transformer decoder layers\n",
    "        features = rearrange(features, \"n b c -> b n c\")\n",
    "        features = self.transformer(features)\n",
    "        features = rearrange(features, \"b n c -> n b c\")\n",
    "\n",
    "        # Remove cls token from features\n",
    "        features = features[1:]\n",
    "\n",
    "        # Regression head: predict pixel values for each patch\n",
    "        patches = self.head.forward(features)\n",
    "        # print(f\"Decoder patches shape: {patches.shape}\")\n",
    "\n",
    "        # Create a mask of the same size as patches, filled with 0's in the tokens\n",
    "        # that we ran through the encoder and 1's in the tokens that were masked\n",
    "        mask = torch.zeros_like(patches)\n",
    "        mask[N_ - 1 :] = 1\n",
    "        mask = take_indices(mask, backward_indices_augmented[1:] - 1)\n",
    "\n",
    "        # Reshape the patches and mask to images ((B, C, H, W) tensors)\n",
    "        img = self.patch2img(patches)\n",
    "        mask = self.patch2img(mask)\n",
    "\n",
    "        return img, mask"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5ug8Hzz_crFC"
   },
   "source": [
    "Finally, the `MAE_ViT` puts it all together. It contains an `MAE_Encoder` and an `MAE_Decoder`. In the forward pass, it takes a batch of images that it passes through the encoder. The decoder then generates (from the output of the encoder) reconstructed images and the corresponding masks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "executionInfo": {
     "elapsed": 47,
     "status": "ok",
     "timestamp": 1740343496108,
     "user": {
      "displayName": "Phuoc Ho Quang",
      "userId": "17998449024561865035"
     },
     "user_tz": -60
    },
    "id": "kJ7gSZLE5SHk"
   },
   "outputs": [],
   "source": [
    "class MAE_ViT(torch.nn.Module):\n",
    "    \"\"\"\n",
    "    Masked Autoencoder with Vision Transformer (MAE-ViT).\n",
    "\n",
    "    Args:\n",
    "        image_size (int): Size of the input image (assumed square: image_size x image_size).\n",
    "        patch_size (int): Size of each image patch.\n",
    "        emb_dim (int): Embedding dimension for tokenized patches.\n",
    "        mlp_ratio (float): Ratio of MLP hidden dimension to embedding dimension.\n",
    "        encoder_layer (int): Number of layers in the encoder.\n",
    "        encoder_head (int): Number of attention heads in the encoder.\n",
    "        decoder_layer (int): Number of layers in the decoder.\n",
    "        decoder_head (int): Number of attention heads in the decoder.\n",
    "        mask_ratio (float): Fraction of patches to mask.\n",
    "\n",
    "    Returns:\n",
    "        Tuple[torch.Tensor, torch.Tensor]:\n",
    "            - predicted_img: Reconstructed image tensor.\n",
    "            - mask: Binary mask tensor indicating masked patches.\n",
    "    \"\"\"\n",
    "    def __init__(\n",
    "        self,\n",
    "        image_size=32,\n",
    "        patch_size=2,\n",
    "        emb_dim=192,\n",
    "        mlp_ratio=4,\n",
    "        encoder_layer=12,\n",
    "        encoder_head=3,\n",
    "        decoder_layer=4,\n",
    "        decoder_head=3,\n",
    "        mask_ratio=0.75,\n",
    "    ) -> None:\n",
    "        super().__init__()\n",
    "        self.encoder = MAE_Encoder(\n",
    "            image_size,\n",
    "            patch_size,\n",
    "            emb_dim,\n",
    "            mlp_ratio,\n",
    "            encoder_layer,\n",
    "            encoder_head,\n",
    "            mask_ratio,\n",
    "        )\n",
    "        self.decoder = MAE_Decoder(\n",
    "            image_size, patch_size, emb_dim, mlp_ratio, decoder_layer, decoder_head\n",
    "        )\n",
    "\n",
    "    def forward(self, img):\n",
    "        \"\"\"\n",
    "        Forward pass of MAE-ViT.\n",
    "\n",
    "        Args:\n",
    "            img (torch.Tensor): Input image tensor of shape (B, C, H, W).\n",
    "\n",
    "        Returns:\n",
    "            Tuple[torch.Tensor, torch.Tensor]:\n",
    "                - predicted_img: (B, C, H, W) Reconstructed image tensor.\n",
    "                - mask: (B, N_patches) Binary mask indicating masked patches.\n",
    "        \"\"\"\n",
    "        # Encode image to obtain latent features and backward_indices\n",
    "        features, backward_indices = self.encoder(img)\n",
    "\n",
    "        # Decode features to reconstruct image\n",
    "        predicted_img, mask = self.decoder(features, backward_indices)\n",
    "        return predicted_img, mask"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Uqo3bDVJuL3F"
   },
   "source": [
    "<br>The `ViT_Classifier` below is the actual model used for classification on the downstream task, using pretrained weights from the `MAE_Encoder` (that can be further fine-tuned). It is a standard ViT, similar to the one we built in the previous lab, except that it is instantiated from an `MAE_Encoder`.\n",
    "\n",
    "Like a standard ViT, it contains a classification head `self.head`, that is a `torch.nn.Linear` layer projecting features ($(B,D)$ tensor) to unnormalized probabilities, *a.k.a.* logits ($(B, K)$ tensor where $K$ is the number of classes).\n",
    "\n",
    "Complete the missing bits in the `__init__` routine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "executionInfo": {
     "elapsed": 14,
     "status": "ok",
     "timestamp": 1740343499128,
     "user": {
      "displayName": "Phuoc Ho Quang",
      "userId": "17998449024561865035"
     },
     "user_tz": -60
    },
    "id": "7SdZGjEcY4Zz"
   },
   "outputs": [],
   "source": [
    "class ViT_Classifier(torch.nn.Module):\n",
    "    \"\"\"\n",
    "    This is a ViT model similar to the one in the previous lab, except that for\n",
    "    instantiation it takes as argument an MAE encoder and copies the relevant layers.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, encoder: MAE_Encoder, num_classes=10, pool=\"cls\") -> None:\n",
    "        super().__init__()\n",
    "\n",
    "        assert pool in {\n",
    "            \"cls\",\n",
    "            \"mean\",\n",
    "        }, \"pool type must be either cls (cls token) or mean (mean pooling)\"\n",
    "        self.pool = pool\n",
    "\n",
    "        # Deep copy of the encoder that was passed as argument,\n",
    "        # so that we don't modify it if we fine-tune\n",
    "        encoder = copy.deepcopy(encoder)\n",
    "\n",
    "        # Retrieve from the encoder the relevant pre-trained layers\n",
    "        self.cls_token = encoder.cls_token\n",
    "        self.pos_embedding = encoder.pos_embedding\n",
    "        self.patchify = encoder.patchify\n",
    "        self.transformer = encoder.transformer\n",
    "        self.layer_norm = encoder.layer_norm\n",
    "\n",
    "        # Add a classification head\n",
    "        D = self.pos_embedding.shape[-1]\n",
    "        self.head = torch.nn.Linear(D, num_classes)\n",
    "\n",
    "        self.init_weight()\n",
    "\n",
    "    def init_weight(self):\n",
    "        trunc_normal_(self.cls_token, std=0.02)\n",
    "        trunc_normal_(self.pos_embedding, std=0.02)\n",
    "\n",
    "    def forward(self, img, detach=False):\n",
    "        B = img.shape[0]\n",
    "\n",
    "        patches = self.patchify(img)\n",
    "        patches = rearrange(patches, \"b c h w -> (h w) b c\")\n",
    "\n",
    "        patches = patches + self.pos_embedding\n",
    "        patches = torch.cat([self.cls_token.expand(-1, B, -1), patches], dim=0)\n",
    "        patches = rearrange(patches, \"n b c -> b n c\")\n",
    "\n",
    "        features = self.layer_norm(self.transformer(patches))\n",
    "        features = rearrange(features, \"b n c -> n b c\")\n",
    "        features = features.mean(dim=0) if self.pool == \"mean\" else features[0]\n",
    "\n",
    "        if detach:\n",
    "            features = features.detach()\n",
    "\n",
    "        logits = self.head(features)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9D1PFmAMVQGc"
   },
   "source": [
    "# Instantiate an MAE model & train it"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "05ixmtDj-SZS"
   },
   "source": [
    "We will use the GPU if it is available on your machine, otherwise the CPU. We do so by putting the model and data on the active device with `.to(device)`. GPU training is 6-10x faster here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 31,
     "status": "ok",
     "timestamp": 1740343501449,
     "user": {
      "displayName": "Phuoc Ho Quang",
      "userId": "17998449024561865035"
     },
     "user_tz": -60
    },
    "id": "wz4dE1aG-MoK",
    "outputId": "fb0432b8-2633-4e8e-d943-402ac312fae3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2PVLE8l7WL53"
   },
   "source": [
    "To keep the model trainable in limited time, we choose the following settings:\n",
    "- We tokenize the input image in $4\\times 4$ patches (3 channels)\n",
    "- We use 6 transformer encoder blocks: because MAE encoders only process a small fraction of the image patches (the non-masked ones), we can afford more encoder blocks than in the previous lab (re: computational budget); it also acts as a form of data augmentation (re: overfitting)\n",
    "- We use 3 transformer decoder blocks\n",
    "- We embed the patch to $D$ dimension, where $D$ preserves the input dimension of the patch (invertible mapping)\n",
    "- We use 3 heads for multihead self-attention layers\n",
    "- We reduce the width of the hidden layers in MLP from the default $4D$ down to $2D$ to reduce the number of parameters\n",
    "\n",
    "Furthermore, we will use a masking ratio of 0.75.\n",
    "\n",
    "<br>To accelerate pre-training, I have already run pretraining for between 20 and 50 epochs for you. You can use those pre-trained weights as a starting point and just pre-train for 5 more epochs. By default, those weights are downloaded down below. You can comment that cell if you want to pre-train from scratch instead."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hOCF_3CNju0O"
   },
   "source": [
    "**Comment:** Here I use pre-trained weights as a starting point, but I would like to train with 10 more epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "executionInfo": {
     "elapsed": 43,
     "status": "ok",
     "timestamp": 1740343578329,
     "user": {
      "displayName": "Phuoc Ho Quang",
      "userId": "17998449024561865035"
     },
     "user_tz": -60
    },
    "id": "OEs-EnXLW1-4"
   },
   "outputs": [],
   "source": [
    "# Training parameters\n",
    "learning_rate = 1e-2\n",
    "weight_decay = 1e-2\n",
    "n_epochs = 20\n",
    "batch_size = 128\n",
    "\n",
    "# Transformer parameters\n",
    "dim = 4 * 4 * 3     # Embedding dimension D\n",
    "enc_depth = 6       # Number of encoder blocks\n",
    "enc_heads = 3       # Number of attention heads in MHSA layers in the encoder\n",
    "dec_depth = 3       # Number of decoder blocks\n",
    "dec_heads = 3       # Number of attention heads in MHSA layers in the decoder\n",
    "mlp_ratio = 2       # Dimension of the hidden layer in MLP layers / dimension of the embedding\n",
    "mask_ratio = 0.75   # Percentage of masked tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1740343578687,
     "user": {
      "displayName": "Phuoc Ho Quang",
      "userId": "17998449024561865035"
     },
     "user_tz": -60
    },
    "id": "2GXvg5HzUs_b"
   },
   "outputs": [],
   "source": [
    "cifar_train_loader = torch.utils.data.DataLoader(\n",
    "    cifar_trainset, batch_size=batch_size, shuffle=True\n",
    ")\n",
    "cifar_test_loader = torch.utils.data.DataLoader(\n",
    "    cifar_testset, batch_size=batch_size, shuffle=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "executionInfo": {
     "elapsed": 54,
     "status": "ok",
     "timestamp": 1740343580122,
     "user": {
      "displayName": "Phuoc Ho Quang",
      "userId": "17998449024561865035"
     },
     "user_tz": -60
    },
    "id": "9h3kQ1NAUtcW"
   },
   "outputs": [],
   "source": [
    "model = MAE_ViT(\n",
    "    image_size=32,\n",
    "    patch_size=4,\n",
    "    emb_dim=dim,\n",
    "    mlp_ratio=mlp_ratio,\n",
    "    encoder_layer=enc_depth,\n",
    "    encoder_head=enc_heads,\n",
    "    decoder_layer=dec_depth,\n",
    "    decoder_head=dec_heads,\n",
    "    mask_ratio=mask_ratio,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "O-ylgI9KiQvi"
   },
   "source": [
    "Download and start from weights obtained after 20 epochs of pre-training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 9459,
     "status": "ok",
     "timestamp": 1740343590428,
     "user": {
      "displayName": "Phuoc Ho Quang",
      "userId": "17998449024561865035"
     },
     "user_tz": -60
    },
    "id": "lZ-Jl_5Ekx3O",
    "outputId": "fd1bf072-7e9f-4285-8c0b-a87bcc22462c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: combining -O with -r or -p will mean that all downloaded content\n",
      "will be placed in the single file you specified.\n",
      "\n",
      "--2025-02-23 20:46:20--  https://drive.google.com/uc?export=download&id=1QYd0aOiku72uGbAiCrAmCwxIaRYxugRo\n",
      "Resolving drive.google.com (drive.google.com)... 64.233.170.102, 64.233.170.139, 64.233.170.113, ...\n",
      "Connecting to drive.google.com (drive.google.com)|64.233.170.102|:443... connected.\n",
      "HTTP request sent, awaiting response... 303 See Other\n",
      "Location: https://drive.usercontent.google.com/download?id=1QYd0aOiku72uGbAiCrAmCwxIaRYxugRo&export=download [following]\n",
      "--2025-02-23 20:46:20--  https://drive.usercontent.google.com/download?id=1QYd0aOiku72uGbAiCrAmCwxIaRYxugRo&export=download\n",
      "Resolving drive.usercontent.google.com (drive.usercontent.google.com)... 172.217.194.132, 2404:6800:4003:c04::84\n",
      "Connecting to drive.usercontent.google.com (drive.usercontent.google.com)|172.217.194.132|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 764711 (747K) [application/octet-stream]\n",
      "Saving to: ‘weights_20.pth’\n",
      "\n",
      "weights_20.pth      100%[===================>] 746.79K  --.-KB/s    in 0.01s   \n",
      "\n",
      "2025-02-23 20:46:23 (51.1 MB/s) - ‘weights_20.pth’ saved [764711/764711]\n",
      "\n",
      "FINISHED --2025-02-23 20:46:23--\n",
      "Total wall clock time: 3.2s\n",
      "Downloaded: 1 files, 747K in 0.01s (51.1 MB/s)\n",
      "WARNING: combining -O with -r or -p will mean that all downloaded content\n",
      "will be placed in the single file you specified.\n",
      "\n",
      "--2025-02-23 20:46:23--  https://drive.google.com/uc?export=download&id=1EuWq_vwjBOOcJC558rZFLkM0ZvZiP6aP\n",
      "Resolving drive.google.com (drive.google.com)... 64.233.170.102, 64.233.170.139, 64.233.170.113, ...\n",
      "Connecting to drive.google.com (drive.google.com)|64.233.170.102|:443... connected.\n",
      "HTTP request sent, awaiting response... 303 See Other\n",
      "Location: https://drive.usercontent.google.com/download?id=1EuWq_vwjBOOcJC558rZFLkM0ZvZiP6aP&export=download [following]\n",
      "--2025-02-23 20:46:24--  https://drive.usercontent.google.com/download?id=1EuWq_vwjBOOcJC558rZFLkM0ZvZiP6aP&export=download\n",
      "Resolving drive.usercontent.google.com (drive.usercontent.google.com)... 172.217.194.132, 2404:6800:4003:c04::84\n",
      "Connecting to drive.usercontent.google.com (drive.usercontent.google.com)|172.217.194.132|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 765684 (748K) [application/octet-stream]\n",
      "Saving to: ‘weights_40.pth’\n",
      "\n",
      "weights_40.pth      100%[===================>] 747.74K  --.-KB/s    in 0.007s  \n",
      "\n",
      "2025-02-23 20:46:27 (99.2 MB/s) - ‘weights_40.pth’ saved [765684/765684]\n",
      "\n",
      "FINISHED --2025-02-23 20:46:27--\n",
      "Total wall clock time: 3.3s\n",
      "Downloaded: 1 files, 748K in 0.007s (99.2 MB/s)\n",
      "WARNING: combining -O with -r or -p will mean that all downloaded content\n",
      "will be placed in the single file you specified.\n",
      "\n",
      "--2025-02-23 20:46:27--  https://drive.google.com/uc?export=download&id=1YjGuZ1OAXmqXYYEcey1mn7Cz1KvJN61P\n",
      "Resolving drive.google.com (drive.google.com)... 64.233.170.102, 64.233.170.139, 64.233.170.113, ...\n",
      "Connecting to drive.google.com (drive.google.com)|64.233.170.102|:443... connected.\n",
      "HTTP request sent, awaiting response... 303 See Other\n",
      "Location: https://drive.usercontent.google.com/download?id=1YjGuZ1OAXmqXYYEcey1mn7Cz1KvJN61P&export=download [following]\n",
      "--2025-02-23 20:46:27--  https://drive.usercontent.google.com/download?id=1YjGuZ1OAXmqXYYEcey1mn7Cz1KvJN61P&export=download\n",
      "Resolving drive.usercontent.google.com (drive.usercontent.google.com)... 172.217.194.132, 2404:6800:4003:c04::84\n",
      "Connecting to drive.usercontent.google.com (drive.usercontent.google.com)|172.217.194.132|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 765684 (748K) [application/octet-stream]\n",
      "Saving to: ‘weights_50.pth’\n",
      "\n",
      "weights_50.pth      100%[===================>] 747.74K  --.-KB/s    in 0.008s  \n",
      "\n",
      "2025-02-23 20:46:29 (94.2 MB/s) - ‘weights_50.pth’ saved [765684/765684]\n",
      "\n",
      "FINISHED --2025-02-23 20:46:29--\n",
      "Total wall clock time: 2.8s\n",
      "Downloaded: 1 files, 748K in 0.008s (94.2 MB/s)\n"
     ]
    }
   ],
   "source": [
    "!wget --no-check-certificate -r 'https://drive.google.com/uc?export=download&id=1QYd0aOiku72uGbAiCrAmCwxIaRYxugRo' -O weights_20.pth\n",
    "!wget --no-check-certificate -r 'https://drive.google.com/uc?export=download&id=1EuWq_vwjBOOcJC558rZFLkM0ZvZiP6aP' -O weights_40.pth\n",
    "!wget --no-check-certificate -r 'https://drive.google.com/uc?export=download&id=1YjGuZ1OAXmqXYYEcey1mn7Cz1KvJN61P' -O weights_50.pth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 66,
     "status": "ok",
     "timestamp": 1740343590505,
     "user": {
      "displayName": "Phuoc Ho Quang",
      "userId": "17998449024561865035"
     },
     "user_tz": -60
    },
    "id": "5FeFHPR9lTV-",
    "outputId": "f972ff6a-ae73-4594-f3fd-3ef0d7dbbe1f"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-19-d3cdbda48ad3>:1: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(\"weights_50.pth\"))\n"
     ]
    }
   ],
   "source": [
    "model.load_state_dict(torch.load(\"weights_50.pth\"))\n",
    "n_epochs = 10\n",
    "learning_rate = 1e-3  # reducing the learning rate if doing a warm restart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "executionInfo": {
     "elapsed": 318,
     "status": "ok",
     "timestamp": 1740343590835,
     "user": {
      "displayName": "Phuoc Ho Quang",
      "userId": "17998449024561865035"
     },
     "user_tz": -60
    },
    "id": "SAXkn--c_G6i"
   },
   "outputs": [],
   "source": [
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3QsC21adidPC"
   },
   "source": [
    "<br> Run the MAE model. The MAE loss is a Mean Squared Error loss between the reconstructed and true images, computed only on the area corresponding to the masked tokens. Divide it by `mask_ratio` to normalize it. Implement it manually using `torch.mean`, `predicted_img`, `img` and `mask`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "executionInfo": {
     "elapsed": 40,
     "status": "ok",
     "timestamp": 1740343590949,
     "user": {
      "displayName": "Phuoc Ho Quang",
      "userId": "17998449024561865035"
     },
     "user_tz": -60
    },
    "id": "lUPJPurEUthg"
   },
   "outputs": [],
   "source": [
    "optimizer = torch.optim.AdamW(\n",
    "    model.parameters(), lr=learning_rate, weight_decay=weight_decay\n",
    ")\n",
    "criterion = torch.nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 162144,
     "status": "ok",
     "timestamp": 1740343754142,
     "user": {
      "displayName": "Phuoc Ho Quang",
      "userId": "17998449024561865035"
     },
     "user_tz": -60
    },
    "id": "XuRzDxYIa0OA",
    "outputId": "c9d26d13-091a-4054-dafe-32ab1213a86c"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0: 100%|██████████| 391/391 [00:18<00:00, 20.89batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: MAE Train Loss: 0.0177\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|██████████| 391/391 [00:15<00:00, 25.05batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: MAE Train Loss: 0.0176\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2: 100%|██████████| 391/391 [00:15<00:00, 25.57batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: MAE Train Loss: 0.0176\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3: 100%|██████████| 391/391 [00:16<00:00, 24.13batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: MAE Train Loss: 0.0176\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 391/391 [00:16<00:00, 23.70batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: MAE Train Loss: 0.0176\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5: 100%|██████████| 391/391 [00:15<00:00, 24.70batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5: MAE Train Loss: 0.0176\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6: 100%|██████████| 391/391 [00:15<00:00, 24.65batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6: MAE Train Loss: 0.0176\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7: 100%|██████████| 391/391 [00:16<00:00, 23.21batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7: MAE Train Loss: 0.0176\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8: 100%|██████████| 391/391 [00:15<00:00, 25.61batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8: MAE Train Loss: 0.0176\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 391/391 [00:15<00:00, 24.52batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: MAE Train Loss: 0.0175\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "model.train()\n",
    "\n",
    "for epoch in range(0, n_epochs):\n",
    "    train_loss = 0.0\n",
    "    all_labels = []\n",
    "    all_predicted = []\n",
    "\n",
    "    with tqdm(cifar_train_loader, unit=\"batch\") as tepoch:\n",
    "        for img, label in tepoch:\n",
    "            tepoch.set_description(f\"Epoch {epoch}\")\n",
    "\n",
    "            # Putting data on device\n",
    "            img = img.to(device)\n",
    "\n",
    "            # Forward and backward passes\n",
    "            predicted_img, mask = model(img)\n",
    "            loss = criterion(predicted_img * mask, img * mask) / mask_ratio\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # Compute the loss\n",
    "            train_loss += loss.item() * len(label)\n",
    "\n",
    "    print(\n",
    "        \"Epoch {}: MAE Train Loss: {:.4f}\".format(\n",
    "            epoch, train_loss / len(cifar_train_loader.dataset)\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Td5K4XTMiiio"
   },
   "source": [
    "<br>Visualize the MAE decoder's predictions on test images:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 846
    },
    "executionInfo": {
     "elapsed": 1169,
     "status": "ok",
     "timestamp": 1740343769515,
     "user": {
      "displayName": "Phuoc Ho Quang",
      "userId": "17998449024561865035"
     },
     "user_tz": -60
    },
    "id": "G1-O_liNcF-U",
    "outputId": "b915fd35-f27d-4758-87da-2ead5b8588cc"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [0.03529412..1.0207821].\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x1000 with 15 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    ids = np.random.choice(len(cifar_testset), 5, replace=False)\n",
    "    val_img = X_test[ids, :].to(device)\n",
    "    predicted_val_img, mask = model(val_img)\n",
    "    predicted_val_img = predicted_val_img * mask + val_img * (1 - mask)\n",
    "    img = torch.stack([val_img * (1 - mask), predicted_val_img, val_img], dim=1)\n",
    "\n",
    "plt.figure(figsize=(6, 10))\n",
    "for idx in range(0, 15):\n",
    "    plt.subplot(5, 3, idx + 1)\n",
    "    row = idx // 3\n",
    "    col = idx - 3 * row\n",
    "    plt.imshow(img[row, col, :, :, :].permute(1, 2, 0).detach().cpu().numpy())\n",
    "    text = \"mask\" if col == 0 else (\"predicted\" if col == 1 else \"image\")\n",
    "    plt.title(text)\n",
    "    plt.grid(False)\n",
    "    plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "So3vIcvS7wr_"
   },
   "source": [
    "# Fine-tuning a pre-trained ViT model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "M0c4-Bg8EOCY"
   },
   "source": [
    "Now that we have pretrained a ViT encoder using Masked Auto-Encoding, we will fine-tune it specifically for the task of object recognition (classification) on the CIFAR-10 dataset.\n",
    "\n",
    "Training the same model *from scratch* for this task, for up to 20 epochs, typically yields a test performance below 60% accuracy with clear signs of overfitting (you can also try it for yourself). Let's see if we can do better, in 5 epochs of fine-tuning, if we start from the MAE pretrained weights."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rDK031kYafcx"
   },
   "source": [
    "<br>Firstly we will reuse two convenience functions from the previous lab:\n",
    "- to transform a class probability tensor to class labels\n",
    "- to compute the prediction accuracy from predicted and ground truth labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1740343777488,
     "user": {
      "displayName": "Phuoc Ho Quang",
      "userId": "17998449024561865035"
     },
     "user_tz": -60
    },
    "id": "WuMqpS9M2xsp"
   },
   "outputs": [],
   "source": [
    "def vector_to_class(x):\n",
    "    y = torch.argmax(F.softmax(x, dim=1), axis=1)\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1740343777646,
     "user": {
      "displayName": "Phuoc Ho Quang",
      "userId": "17998449024561865035"
     },
     "user_tz": -60
    },
    "id": "wgXdu5xJ2y2E"
   },
   "outputs": [],
   "source": [
    "def prediction_accuracy(predict, labels):\n",
    "    accuracy = (predict == labels).sum() / (labels.shape[0])\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xj9jj01nBMA2"
   },
   "source": [
    "<br>We define the parameters for this fine-tuning step:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "executionInfo": {
     "elapsed": 18,
     "status": "ok",
     "timestamp": 1740343782673,
     "user": {
      "displayName": "Phuoc Ho Quang",
      "userId": "17998449024561865035"
     },
     "user_tz": -60
    },
    "id": "AnN1Uck7817z"
   },
   "outputs": [],
   "source": [
    "# Training parameters\n",
    "learning_rate = 1e-3\n",
    "weight_decay = 1e-2\n",
    "n_epochs = 10\n",
    "batch_size = 128\n",
    "\n",
    "# Model parameters\n",
    "num_classes = 10\n",
    "pool = \"cls\"  # 'mean'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "executionInfo": {
     "elapsed": 14,
     "status": "ok",
     "timestamp": 1740343782891,
     "user": {
      "displayName": "Phuoc Ho Quang",
      "userId": "17998449024561865035"
     },
     "user_tz": -60
    },
    "id": "FLX42JYv_VQD"
   },
   "outputs": [],
   "source": [
    "cifar_train_loader = torch.utils.data.DataLoader(\n",
    "    cifar_trainset, batch_size=batch_size, shuffle=True\n",
    ")\n",
    "cifar_test_loader = torch.utils.data.DataLoader(\n",
    "    cifar_testset, batch_size=batch_size, shuffle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "I0ACZkTFW1-7"
   },
   "source": [
    "<br>Now, we instantiate a ViT model with the desired parameters, with the pretrained weights of the MAE pre-training:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "executionInfo": {
     "elapsed": 561,
     "status": "ok",
     "timestamp": 1740343783895,
     "user": {
      "displayName": "Phuoc Ho Quang",
      "userId": "17998449024561865035"
     },
     "user_tz": -60
    },
    "id": "RmbX6oq0W1-7"
   },
   "outputs": [],
   "source": [
    "# Define the ViT model (to be fine-tuned) with the correct arguments:\n",
    "cifar_model_ft = ViT_Classifier(\n",
    "    encoder=model.encoder, num_classes=num_classes, pool=pool\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "executionInfo": {
     "elapsed": 9,
     "status": "ok",
     "timestamp": 1740343783907,
     "user": {
      "displayName": "Phuoc Ho Quang",
      "userId": "17998449024561865035"
     },
     "user_tz": -60
    },
    "id": "hbVS5rObA34x"
   },
   "outputs": [],
   "source": [
    "cifar_model_ft = cifar_model_ft.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KUmQKIEe8_QU"
   },
   "source": [
    "<br>Now, we carry out training on the CIFAR10 dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "executionInfo": {
     "elapsed": 10,
     "status": "ok",
     "timestamp": 1740343784437,
     "user": {
      "displayName": "Phuoc Ho Quang",
      "userId": "17998449024561865035"
     },
     "user_tz": -60
    },
    "id": "LA4Tke1vZECT"
   },
   "outputs": [],
   "source": [
    "criterion = torch.nn.CrossEntropyLoss(reduction=\"sum\")\n",
    "optimizer = torch.optim.AdamW(\n",
    "    cifar_model_ft.parameters(), lr=learning_rate, weight_decay=weight_decay\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 134602,
     "status": "ok",
     "timestamp": 1740343919838,
     "user": {
      "displayName": "Phuoc Ho Quang",
      "userId": "17998449024561865035"
     },
     "user_tz": -60
    },
    "id": "pyEwLnLR9gv0",
    "outputId": "d3ffd0b8-3fb2-4ec3-bf23-d977872d68b7"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0: 100%|██████████| 391/391 [00:15<00:00, 26.01batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: Train Loss: 1.5171\n",
      "Epoch 0: Train Accuracy: 0.4489\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|██████████| 391/391 [00:12<00:00, 30.08batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Train Loss: 1.1762\n",
      "Epoch 1: Train Accuracy: 0.5750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2: 100%|██████████| 391/391 [00:13<00:00, 29.93batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: Train Loss: 1.0636\n",
      "Epoch 2: Train Accuracy: 0.6151\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3: 100%|██████████| 391/391 [00:13<00:00, 29.88batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: Train Loss: 0.9836\n",
      "Epoch 3: Train Accuracy: 0.6448\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 391/391 [00:13<00:00, 29.75batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: Train Loss: 0.9266\n",
      "Epoch 4: Train Accuracy: 0.6668\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5: 100%|██████████| 391/391 [00:13<00:00, 29.77batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5: Train Loss: 0.8851\n",
      "Epoch 5: Train Accuracy: 0.6817\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6: 100%|██████████| 391/391 [00:13<00:00, 29.69batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6: Train Loss: 0.8416\n",
      "Epoch 6: Train Accuracy: 0.6980\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7: 100%|██████████| 391/391 [00:13<00:00, 28.23batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7: Train Loss: 0.8144\n",
      "Epoch 7: Train Accuracy: 0.7076\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8: 100%|██████████| 391/391 [00:13<00:00, 29.15batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8: Train Loss: 0.7813\n",
      "Epoch 8: Train Accuracy: 0.7202\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 391/391 [00:13<00:00, 28.75batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: Train Loss: 0.7540\n",
      "Epoch 9: Train Accuracy: 0.7317\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "cifar_model_ft.train()\n",
    "\n",
    "for epoch in range(0, n_epochs):\n",
    "    train_loss = 0.0\n",
    "    all_labels = []\n",
    "    all_predicted = []\n",
    "\n",
    "    with tqdm(cifar_train_loader, unit=\"batch\") as tepoch:\n",
    "        for imgs, labels in tepoch:\n",
    "            tepoch.set_description(f\"Epoch {epoch}\")\n",
    "\n",
    "            # Put data on device\n",
    "            imgs = imgs.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            # Forward and backward passes\n",
    "            predict = cifar_model_ft(imgs)  # predicted logits\n",
    "            loss = criterion(predict, labels)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # Compute the loss\n",
    "            train_loss += loss.item()\n",
    "            # Store labels and class predictions\n",
    "            all_labels.extend(labels.tolist())\n",
    "            all_predicted.extend(vector_to_class(predict).tolist())\n",
    "\n",
    "    print(\n",
    "        \"Epoch {}: Train Loss: {:.4f}\".format(\n",
    "            epoch, train_loss / len(cifar_train_loader.dataset)\n",
    "        )\n",
    "    )\n",
    "    print(\n",
    "        \"Epoch {}: Train Accuracy: {:.4f}\".format(\n",
    "            epoch, prediction_accuracy(np.array(all_predicted), np.array(all_labels))\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "s1MCXQIcZYF5"
   },
   "source": [
    "<br>Let's compute the test accuracy, and check that it is indeed a lot better than training from scratch (<60%)!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1998,
     "status": "ok",
     "timestamp": 1740343925891,
     "user": {
      "displayName": "Phuoc Ho Quang",
      "userId": "17998449024561865035"
     },
     "user_tz": -60
    },
    "id": "a8VvPS8WQ92b",
    "outputId": "2b082c68-21e5-4d05-9d0b-d857eef3232f"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 79/79 [00:01<00:00, 39.81batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test Accuracy: 0.6784\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "cifar_model_ft.eval()\n",
    "\n",
    "all_predicted = []\n",
    "all_labels = []\n",
    "\n",
    "with tqdm(cifar_test_loader, unit=\"batch\") as tepoch:\n",
    "    for imgs, labels in tepoch:\n",
    "        all_labels.extend(labels.tolist())\n",
    "\n",
    "        imgs = imgs.to(device)\n",
    "        predict = cifar_model_ft(imgs)\n",
    "        all_predicted.extend(vector_to_class(predict).tolist())\n",
    "\n",
    "test_accuracy = prediction_accuracy(np.array(all_predicted), np.array(all_labels))\n",
    "\n",
    "print(\"\\nTest Accuracy:\", test_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vLFpuasOBWcv"
   },
   "source": [
    "## Linear-Probing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MDE62z0BZE3n"
   },
   "source": [
    "In the previous section, we have allowed all parameters of the ViT to be further fine-tuned given supervised data.\n",
    "\n",
    "Linear-probing is an alternative to fine-tuning. In linear-probing, most of the parameters of the transformer backbone are frozen after pre-training. The only parameters that are still trainable are those of the linear classification head. In linear-probing, the learnt model is essentially a linear classifier that takes as features a pretrained deep representation.\n",
    "\n",
    "<br>Linear probing often provides poorer results than fine-tuning (but for a smaller computational budget). This will be true in particular when doing MAE pre-training. Let's verify this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "executionInfo": {
     "elapsed": 8,
     "status": "ok",
     "timestamp": 1740343946423,
     "user": {
      "displayName": "Phuoc Ho Quang",
      "userId": "17998449024561865035"
     },
     "user_tz": -60
    },
    "id": "k4oGFae7DxJI"
   },
   "outputs": [],
   "source": [
    "# Training parameters\n",
    "learning_rate = 1e-3\n",
    "weight_decay = 1e-2\n",
    "n_epochs = 10\n",
    "batch_size = 128\n",
    "\n",
    "# Model parameters\n",
    "num_classes = 10\n",
    "pool = \"mean\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1740343946777,
     "user": {
      "displayName": "Phuoc Ho Quang",
      "userId": "17998449024561865035"
     },
     "user_tz": -60
    },
    "id": "PwZSOZdgTTAI"
   },
   "outputs": [],
   "source": [
    "cifar_train_loader = torch.utils.data.DataLoader(\n",
    "    cifar_trainset, batch_size=batch_size, shuffle=True\n",
    ")\n",
    "cifar_test_loader = torch.utils.data.DataLoader(\n",
    "    cifar_testset, batch_size=batch_size, shuffle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "executionInfo": {
     "elapsed": 17,
     "status": "ok",
     "timestamp": 1740343947180,
     "user": {
      "displayName": "Phuoc Ho Quang",
      "userId": "17998449024561865035"
     },
     "user_tz": -60
    },
    "id": "6NtyvkxUrB43"
   },
   "outputs": [],
   "source": [
    "cifar_model_lp = ViT_Classifier(\n",
    "    encoder=model.encoder, num_classes=num_classes, pool=pool\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "executionInfo": {
     "elapsed": 8,
     "status": "ok",
     "timestamp": 1740343947568,
     "user": {
      "displayName": "Phuoc Ho Quang",
      "userId": "17998449024561865035"
     },
     "user_tz": -60
    },
    "id": "4tF4sSOJCCLl"
   },
   "outputs": [],
   "source": [
    "cifar_model_lp = cifar_model_lp.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jWWaGGaUlD8z"
   },
   "source": [
    "<br>Training proceeds similarly to the fine-tuning case, except only the parameters of the ViT `head` should be trained. You can copy-paste the code from the previous section and adapt it. In particular, you should use the `detach=True` argument in the forward call to the model, so that the transformer encoder's parameters (except the classification head) are not backpropagated to."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1740343949000,
     "user": {
      "displayName": "Phuoc Ho Quang",
      "userId": "17998449024561865035"
     },
     "user_tz": -60
    },
    "id": "vdLqMtmNBgwM"
   },
   "outputs": [],
   "source": [
    "criterion = torch.nn.CrossEntropyLoss(reduction=\"sum\")\n",
    "optimizer = torch.optim.AdamW(\n",
    "    cifar_model_lp.head.parameters(), lr=learning_rate, weight_decay=weight_decay\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 108903,
     "status": "ok",
     "timestamp": 1740344058093,
     "user": {
      "displayName": "Phuoc Ho Quang",
      "userId": "17998449024561865035"
     },
     "user_tz": -60
    },
    "id": "NdVWCp7HBoDE",
    "outputId": "e2698b10-6fbf-4f7f-e3fe-31fec6f28385"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0: 100%|██████████| 391/391 [00:11<00:00, 34.21batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: Train Loss: 2.0666\n",
      "Epoch 0: Train Accuracy: 0.2993\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|██████████| 391/391 [00:10<00:00, 35.79batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Train Loss: 1.8441\n",
      "Epoch 1: Train Accuracy: 0.3765\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2: 100%|██████████| 391/391 [00:10<00:00, 36.02batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: Train Loss: 1.7536\n",
      "Epoch 2: Train Accuracy: 0.3931\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3: 100%|██████████| 391/391 [00:10<00:00, 35.89batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: Train Loss: 1.7036\n",
      "Epoch 3: Train Accuracy: 0.4041\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 391/391 [00:10<00:00, 35.88batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: Train Loss: 1.6715\n",
      "Epoch 4: Train Accuracy: 0.4135\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5: 100%|██████████| 391/391 [00:10<00:00, 35.84batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5: Train Loss: 1.6489\n",
      "Epoch 5: Train Accuracy: 0.4185\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6: 100%|██████████| 391/391 [00:10<00:00, 37.10batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6: Train Loss: 1.6318\n",
      "Epoch 6: Train Accuracy: 0.4226\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7: 100%|██████████| 391/391 [00:10<00:00, 36.51batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7: Train Loss: 1.6186\n",
      "Epoch 7: Train Accuracy: 0.4269\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8: 100%|██████████| 391/391 [00:10<00:00, 36.03batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8: Train Loss: 1.6079\n",
      "Epoch 8: Train Accuracy: 0.4307\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 391/391 [00:10<00:00, 36.18batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: Train Loss: 1.5988\n",
      "Epoch 9: Train Accuracy: 0.4340\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "cifar_model_lp.train()\n",
    "for param in cifar_model_lp.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "for param in cifar_model_lp.head.parameters():\n",
    "    param.requires_grad = True\n",
    "\n",
    "for epoch in range(0, n_epochs):\n",
    "    train_loss = 0.0\n",
    "    all_labels = []\n",
    "    all_predicted = []\n",
    "\n",
    "    with tqdm(cifar_train_loader, unit=\"batch\") as tepoch:\n",
    "        for imgs, labels in tepoch:\n",
    "            tepoch.set_description(f\"Epoch {epoch}\")\n",
    "\n",
    "            # Put data on device\n",
    "            imgs = imgs.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            # Forward and backward passes\n",
    "            predict = cifar_model_lp(img=imgs, detach=True)  # predicted logits\n",
    "            loss = criterion(predict, labels)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # Compute the loss\n",
    "            train_loss += loss.item()\n",
    "            # Store labels and class predictions\n",
    "            all_labels.extend(labels.tolist())\n",
    "            all_predicted.extend(vector_to_class(predict).tolist())\n",
    "\n",
    "    print(\n",
    "        \"Epoch {}: Train Loss: {:.4f}\".format(\n",
    "            epoch, train_loss / len(cifar_train_loader.dataset)\n",
    "        )\n",
    "    )\n",
    "    print(\n",
    "        \"Epoch {}: Train Accuracy: {:.4f}\".format(\n",
    "            epoch, prediction_accuracy(np.array(all_predicted), np.array(all_labels))\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "--1_eGNdllpS"
   },
   "source": [
    "<br>Compute the accuracy on the test dataset like before:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2255,
     "status": "ok",
     "timestamp": 1740344063211,
     "user": {
      "displayName": "Phuoc Ho Quang",
      "userId": "17998449024561865035"
     },
     "user_tz": -60
    },
    "id": "3nXoFk9tDf3G",
    "outputId": "db69eea8-f352-4139-8f60-1a356ccb6b4a"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 79/79 [00:02<00:00, 35.02batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test Accuracy: 0.4371\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "cifar_model_lp.eval()\n",
    "\n",
    "all_predicted = []\n",
    "all_labels = []\n",
    "\n",
    "with tqdm(cifar_test_loader, unit=\"batch\") as tepoch:\n",
    "    for imgs, labels in tepoch:\n",
    "        all_labels.extend(labels.tolist())\n",
    "\n",
    "        imgs = imgs.to(device)\n",
    "        predict = cifar_model_lp(imgs)\n",
    "        all_predicted.extend(vector_to_class(predict).tolist())\n",
    "\n",
    "test_accuracy = prediction_accuracy(np.array(all_predicted), np.array(all_labels))\n",
    "\n",
    "print(\"\\nTest Accuracy:\", test_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PYFvJIJme2rX"
   },
   "source": [
    "We lost more than 20 points of accuracy. Still, the performance remains reasonable for a 10 class problem considering that we essentially trained a linear model.\n",
    "\n",
    "MAEs with larger decoder depth typically perform a bit better in linear-probing than MAE models with shallow decoders. Still, MAE is often not the strongest self-supervised learning approach to use in combination with linear-probing.\n",
    "\n",
    "<br>Nevertheless, it goes without saying that with a higher computational budget, a deeper/wider ViT, and proper use of data augmentation and regularization, much better results can be achieved on this CIFAR-10 dataset exactly with the type of method that we have seen today!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zx935Lw0FOcv"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
